eval:
  enabled: True
  # use this to evaluate the model over longer rollouts, every so many validation batches
  rollout: 12
  # do the eval every so many batches
  frequency: 5
  # number of bins for the spread-skill metric
  num_bins: 101

plot:
  enabled: True
  scatter: False # If True, scatter plots will be created otherwise Hexbin (More efficient, less sharp) plots will be created
  asynchronous: True # If True, the plotting will be done in a separate thread using asyncio
  frequency: 750
  sample_idx: 0
  per_sample: 6
  parameters:
    - z_500
    - t_850
    - u_850
    - v_850
    - 2t
    - 10u
    - 10v
    - sp
    - tp
    - cp
  #Defining the accumulation levels for precipitation related fields and the colormap
  learned_features: False
  parameters_histogram: ['tp', 'cp']
  accumulation_levels_plot: [-0.2, 0, 0.05, 0.1, 0.25, 0.5, 1, 1.5, 2, 4, 6, 8, 10, 15, 20, 40, 70, 100] # in mm
  cmap_accumulation: ["#000000", "#ffffff", "#04e9e7", "#019ff4", "#0300f4", "#02fd02", "#01c501", "#008e00", "#fdf802", "#e5bc00", "#fd9500", "#fd0000", "#d40000", "#bc0000", "#f800fd", "#8e01c5", "#ff6666", "#ff3333"]
  parameters_spectrum: []
  parameter_groups:
  moisture: [tp, cp, tcw, sf]
  sfc_wind: [10u, 10v, 100u, 100v]
  land: [swvl1, swvl2, stl1, stl2, ssrd, strd, ro]
  cloud: [tcc, hcc, mcc, lcc]

debug:
  # this will detect and trace back NaNs / Infs etc. but will slow down training
  anomaly_detection: False

# activate the pytorch profiler (disable this in production)
# remember to also activate the tensorboard logger (below)
profiler: False

checkpoint:
  every_n_minutes:
    save_frequency: 30 # Approximate, as this is checked at the end of training steps
    num_models_saved: 3   # If set to k, saves the 'last' k model weights in the training.

  every_n_epochs:
    save_frequency: 1
    num_models_saved: -1  # If set to -1, all checkpoints are kept ensuring runs can be continued/forked at any point in the training process

  every_n_train_steps:
    save_frequency: null # Does not scale with rollout
    num_models_saved: 0

log:
  interval: 100
  mlflow:
    enabled: True
    offline: True
    authentication: False
    log_model: False
    tracking_uri: 'https://mlflow.copernicus-climate.eu'
    # tracking_uri: ${hardware.paths.logs.mlflow} to be used for resuming offline runs
    experiment_name: 'aifs-ens'
    project_name: 'AIFS'
    system: True
    terminal: True
    run_name: null
  tensorboard:
    enabled: False
    run_name: ${diagnostics.log.mlflow.run_name}
    experiment_name: ${diagnostics.log.mlflow.experiment_name}
    project_name: null
    log_weights:
      enabled: False
      freq: 1
      interval: 'batch'
    log_gradients:
      enabled: False
      freq: 1
      # interval fixed to 'batch'
    log_clipped_gradients:
      enabled: False
      freq: 1
      # interval fixed to 'batch'
    log_preds:
      enabled: False
      freq: 1
    log_postproc_preds:
      enabled: False
      freq: 1
      # interval fixed to 'batch'
  wandb:
    enabled: False
    offline: False
    log_model: False
    # logger options (these probably come with some overhead)
    gradients: False
    parameters: False

print_memory_summary: False
enable_progress_bar: True
