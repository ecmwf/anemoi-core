# configuration for the "graphtransformed_2g_n320" benchmark
config_validation: False # I want to disable validation

hardware:
  accelerator: cuda
  num_gpus_per_node: 2
  num_nodes: 1
  num_gpus_per_model: 2
  files:
    dataset:  aifs-ea-an-oper-0001-mars-n320-1979-2023-6h-v8.zarr
    graph: graphtransformer-bm-graph.pt  #TODO change to store under anemoi-integration-tests/... so it is resused across processes
  paths:
    data:  /home/mlx/ai-ml/datasets/

dataloader:
  num_workers:
    training: 8
    validation: 8
  limit_batches:
    training: 100
    validation: 0
  training:
    end: 2020-11-30
  validation:
    start: 2020-12-31
  batch_size:
    training: 1
    validation: 1

graph:
  overwrite: False
  nodes:
    hidden:
      node_builder:
        resolution: 6

model:
  encoder:
    num_chunks: 2
  decoder:
    num_chunks: 2
  processor:
    num_chunks: 2
  num_channels: 1024

training:
  max_epochs: 1
  num_sanity_val_steps: 0

diagnostics:
  callbacks: []
  enable_checkpointing: False
  print_memory_summary: true
  benchmark_profiler:
    memory:
      enabled: true
    time:
      verbose: true
    model_summary:
      enabled: false
    snapshot:
      enabled: true
    system:
      enabled: false #some error about metric key in extract_gpu_metrics being invalid
  log:
    mlflow:
      enabled: true
      offline: True
      tracking_uri: ""
    interval: 1
