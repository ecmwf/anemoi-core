---
defaults:
  - layer_kernels: default
  - sample: downscaling
  - mappers: dynamic_graphtransformer


num_channels: 1024
cpu_offload: False
keep_batch_sharded: True
output_mask: null # moved this to config.training to have one mask per output


model:
  _target_: anemoi.models.models.mult_encoder_processor_decoder.AnemoiMultiModel
  emb_data:
    _target_: anemoi.models.layers.mlp.MLP
    hidden_dim: 128
    n_extra_layers: 0
    final_activation: GELU
    layer_kernels: ${model.layer_kernels}
  encoders:
  - name: enc
    mapper: ${model.mappers.encoder}
    sources: [ "lowres" ]
    num_channels: ${model.num_channels}
  merge_latents: average # options: average, sum, concatenation
  hidden_name: "hidden"
  processor: ${model.mappers.processor}
  decoders:
  - name: dec
    mapper: ${model.mappers.decoder}
    sources: [ "hires" ]
    num_channels: ${model.num_channels}


trainable_parameters:
  data: 0
  hidden: 0
  data2hidden: 0
  hidden2data: 0
  hidden2hidden: 0 # GNN and GraphTransformer Processor only


attributes:
  edges:
  - edge_length
  - edge_dirs
  nodes: []

# Bounding configuration
bounding: #These are applied in order

  # Bound tp (total precipitation) with a Relu bounding layer
  # ensuring a range of [0, infinity) to avoid negative precipitation values.
  - _target_: anemoi.models.layers.bounding.ReluBounding #[0, infinity)
    variables:
    - tp
    # - era5.tp # it would be nice to support this

  # [OPTIONAL] Bound cp (convective precipitation) as a fraction of tp.
  # This guarantees that cp is physically consistent with tp by restricting cp
  # to a fraction of tp [0 to 1]. Uncomment the lines below to apply.
  # NOTE: If this bounding strategy is used, the normalization of cp must be
  # changed to "std" normalization, and the "cp" statistics should be remapped
  # to those of tp to ensure consistency.

  # - _target_: anemoi.models.layers.bounding.FractionBounding # fraction of tp
  #   variables:
  #   - cp
  #   min_val: 0
  #   max_val: 1
  #   total_var: tp

  # [OPTIONAL] NormalizedReluBounding
  # This is an extension of the Relu bounding in case the thrshold to be used
  # is not 0. For example, in case of the sea surface temperature we don't use
  # [0, infinity), buth rather [-2C, infinity). We do not want the water
  # temperature to be below the freezing temperature.

  # - _target_: anemoi.models.layers.bounding.NormalizedReluBounding
  #   variables: [sst]
  #   min_val: [-2]
  #   normalizer: ['mean-std']
