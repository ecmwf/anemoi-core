defaults:
- data: zarr
- dataloader: native_grid
- datamodule: ens
- diagnostics: evaluation
- hardware: example
- graph: encoder_decoder_only
- model: transformer_ens
- training: default
- _self_

config_validation: False

### This file is for local experimentation.
##  When you commit your changes, assign the new features and keywords
##  to the correct defaults.
# For example to change from default GPU count:
# hardware:
#   num_gpus_per_node: 1

hardware:
  paths:
    truncation: /leonardo_work/DestE_340_25/ai-ml-slang000/inter_mat/
    data: /leonardo_work/DestE_340_25/ai-ml/datasets/
    output: ${oc.env:SCRATCH}/aifs/${data.resolution}/
  files:
    truncation: ${data.resolution}-o32-linear.mat.npz
    truncation_inv: o32-${data.resolution}-linear.mat.npz
    graph: graph_anemoi_new_${data.resolution}.pt
    dataset: aifs-ea-an-oper-0001-mars-${data.resolution}-1979-2022-6h-v6.zarr
  accelerator: auto
  num_gpus_per_node: ${oc.decode:${oc.env:SLURM_GPUS_PER_NODE}}
  num_nodes: ${oc.decode:${oc.env:SLURM_NNODES}}
  num_gpus_per_ensemble: 1
  num_gpus_per_model: 1

model:
  output_mask: null
  num_channels: 128 #512
  processor:
    num_layers: 8
    num_heads: 4 #8
    window_size: 608
  encoder:
    num_heads: 4 #8
  decoder:
    num_heads: 4 #8

dataloader:
  num_workers:
    training: 2
    validation: 2
    test: 1
  batch_size:
    training: 2
    validation: 2
    test: 2
  limit_batches:
    training: 100
    validation: 100

data:
  resolution: o96

training:
  model_task: anemoi.training.train.forecaster.GraphEnsForecaster
  strategy:
    _target_: anemoi.training.distributed.strategy.DDPEnsGroupStrategy
    num_gpus_per_ensemble: ${hardware.num_gpus_per_ensemble}
    num_gpus_per_model: ${hardware.num_gpus_per_model}
  ensemble_size_per_device: 2
  max_epochs: 1

  precision: bf16-mixed

  optimizer:
    zero: False
    kwargs:
      weight_decay: 0.1
      betas: [0.9, 0.95]
      eps: 1e-7

  pressure_level_scaler:
    _target_: anemoi.training.data.scaling.ReluPressureLevelScaler
    minimum: 0.2
    slope: 0.001

  # loss function for the model
  training_loss:
    # loss class to initialise, can be anything subclassing torch.nn.Module
    _target_: anemoi.training.losses.kcrps.AlmostFairKernelCRPS
    # other kwargs
    scalars: ['variable']
    ignore_nans: False
    alpha: 1.0

  validation_metrics:
    # loss class to initialise, can be anything subclassing torch.nn.Module
    - _target_: anemoi.training.losses.kcrps.KernelCRPS
      # other kwargs
      scalars: []
      ignore_nans: False
      fair: True
    - _target_: anemoi.training.losses.kcrps.AlmostFairKernelCRPS
      scalars: []
      ignore_nans: False
      alpha: 0.95
    - _target_: anemoi.training.losses.kcrps.AlmostFairKernelCRPS
      scalars: []
      ignore_nans: False
      alpha: 1.0

diagnostics:
  plot:
    callbacks: []
  log:
    interval: 4
    wandb:
      entity: 'ecmwf'
    mlflow:
      enabled: True
      offline: True
      experiment_name: 'zdebug112'
      authentication: True
      tracking_uri: 'https://mlflow.ecmwf.int'
      run_name: 'debug12343'
  profiler: False
  enable_progress_bar: True
